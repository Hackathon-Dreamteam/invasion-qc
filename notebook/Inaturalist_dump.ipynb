{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd912cb1-8064-4593-9525-e6fa3d1de77e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Import Required Libraries\n",
    "Import the necessary libraries, including requests and pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ecc5d9de-d228-46a6-b50a-1de9e0789684",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pyinaturalist import get_observations\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c4904f4d-b7cd-4ea4-b98c-6b8b67c128cc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Send GET Request to iNaturalist API\n",
    "Use the requests library to send a GET request to the iNaturalist API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e70be017-1cf5-4fba-ba9a-d4d00abb7785",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "laval_place_id = 27655\n",
    "montreal_place_id = 187355\n",
    "gatineau_place_id = 142292\n",
    "\n",
    "# Initialize an empty DataFrame to store the observations\n",
    "def get_observations_dataframe(place_id,place_name):\n",
    "    df = pd.DataFrame()\n",
    "    for page in range(1, 10):\n",
    "        observation = get_observations(place_id=place_id, verifiable=True,per_page=200, page=str(page), quality_grade=\"research\")\n",
    "        df = df.append(observation[\"results\"], ignore_index=True)\n",
    "        df[\"location\"] = place_name\n",
    "    return df\n",
    "\n",
    "df_naturalist = pd.DataFrame()\n",
    "# Example usage\n",
    "data_laval = get_observations_dataframe(laval_place_id,\"Laval\")\n",
    "data_montreal = get_observations_dataframe(montreal_place_id,\"Montreal\")\n",
    "data_gatineau = get_observations_dataframe(gatineau_place_id,\"Gatineau\")\n",
    "\n",
    "\n",
    "df_naturalist = pd.concat([data_laval, data_montreal, data_gatineau], ignore_index=True)\n",
    "df_naturalist['observed_on'] = pd.to_datetime(df_naturalist['observed_on'], utc=True)\n",
    "\n",
    "# Save the DataFrame to Parquet\n",
    "df_naturalist.to_parquet(\"naturalist_sample.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bfb4ace4-b5b8-47cf-97e0-c4465df6113e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Initialize an empty DataFrame to store the observations\n",
    "def get_observations_dataframe_by_geojson(latitude,longitude):\n",
    "    df = pd.DataFrame()\n",
    "    for page in range(1, 2):\n",
    "        observation = get_observations(verifiable=True,per_page=200, page=str(page), quality_grade=\"research\", lat=latitude, lng= longitude,radius=50)\n",
    "        df = df.append(observation[\"results\"], ignore_index=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "data_shawinigan = get_observations_dataframe_by_geojson(46.67892,-72.876228)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0a18af7-58e6-43ab-94c8-3204462c6c53",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Building Observations Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47962d5e-fb21-4849-a491-fa7d1702f2bb",
     "showTitle": true,
     "title": "converting observed_on date to String"
    }
   },
   "outputs": [],
   "source": [
    "df_naturalist = pd.read_parquet(\"naturalist_sample.parquet\")\n",
    "display(df_naturalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08899fc8-0fc4-4f68-8514-cfe5add6330c",
     "showTitle": true,
     "title": "Import Sentinelle Dataset CSV file"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get all files in the data folder\n",
    "# Read the 'sentinelle_liste_sp.csv' file from the workspace\n",
    "file_path = 'sentinelle_liste_sp.csv'\n",
    "df_sentinelle = pd.read_csv(file_path)\n",
    "# Filter the files based on the ones that contain \"sentinelle\" in their name\n",
    "\n",
    "# display(df_sentinelle)\n",
    "# Add any additional code here for further processing or analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02aa3733-7bc3-4991-b2a7-f2fa53f46a0a",
     "showTitle": true,
     "title": "Add invasive column"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def add_isInvasive_column(df_inaturalist, df_sentinelle):\n",
    "    cols_to_return = list(df_inaturalist)\n",
    "    cols_to_return.append(\"isInvasive\")\n",
    "    df_inaturalist['species_guess'] = df_inaturalist[['species_guess']].apply(lambda x: x.astype(str).str.lower())\n",
    "    df_sentinelle[\"Nom_francais\"] = df_sentinelle[['Nom_francais']].apply(lambda x: x.astype(str).str.lower())\n",
    "    merged_df = df_inaturalist.merge(right=df_sentinelle, left_on='species_guess', right_on='Nom_francais', how='left')\n",
    "    merged_df[\"isInvasive\"] = np.where((merged_df[\"Nom_francais\"].isnull()) | (merged_df[\"Nom_francais\"] == np.nan), False, True)\n",
    "    return merged_df[cols_to_return]\n",
    "\n",
    "# joined_df = add_isInvasive_column(df_naturalist, df_sentinelle)\n",
    "# joined_df[joined_df[\"isInvasive\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b73efa0-b653-472c-9105-76b1478fe507",
     "showTitle": true,
     "title": "Get community column"
    }
   },
   "outputs": [],
   "source": [
    "# Keep only the 'species_guess' column and add a new column with the value 'Laval'\n",
    "# Convert the values in the 'species_guess' column to lowercase and select only the 'species_guess' column\n",
    "\n",
    "def get_community_observations_df(df_naturalist, df_sentinelle):\n",
    "    df = df_naturalist.copy()\n",
    "    df[\"id\"] = \"c_\" + df[\"id\"].astype(str)\n",
    "    df[\"observed_on\"] = df[\"observed_on\"].dt.strftime(\"%Y-%m-%d\")\n",
    "    df.rename(columns={'observed_on': 'observation_date'}, inplace=True)\n",
    "    df['species_guess'] = df['species_guess'].astype(str).str.lower()\n",
    "    df = add_isInvasive_column(df, df_sentinelle)\n",
    "    df['longitude'] = df['geojson'].apply(lambda x: x['coordinates'][0] if 'coordinates' in x else None)\n",
    "    df['latitude'] = df['geojson'].apply(lambda x: x['coordinates'][1] if 'coordinates' in x else None)\n",
    "    df[\"source\"] = \"Community\"\n",
    "    df[\"image_url\"] = df['observation_photos'].apply(lambda x: x[0]['photo'][\"url\"].replace(\"square.jpeg\", \"large.jpeg\") if len(x) >= 1 else None)\n",
    "    df = df[['id', 'species_guess', 'location', 'observation_date', 'isInvasive', 'latitude', 'longitude', 'source', 'image_url']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77170415-ac3e-4ded-a6b2-aa6797a9a9d0",
     "showTitle": true,
     "title": "Get government data"
    }
   },
   "outputs": [],
   "source": [
    "def get_government_observations(df):\n",
    "    df['id'] = \"g_\" + df[\"properties\"].apply(lambda x: str(x['OBJECTID']) if 'OBJECTID' in x else None)\n",
    "    df[\"species_guess\"] = df[\"properties\"].apply(lambda x: x['Nom_espece_français'].lower() if 'Nom_espece_français' in x else None)\n",
    "    df[\"location\"] = df[\"properties\"].apply(lambda x: x['Nom_region_administrative'] if 'Nom_region_administrative' in x else None)\n",
    "    df['location'] = df['location'].replace(\"Montréal\", \"Montreal\").replace(\"Outaouais\", \"Gatineau\")\n",
    "    df[\"observation_date\"] = df[\"properties\"].apply(lambda x: x['Date_observation'] if 'Date_observation' in x else None)\n",
    "    df[\"latitude\"] = df[\"properties\"].apply(lambda x: x['Latitude'] if 'Latitude' in x else None)\n",
    "    df[\"longitude\"] = df[\"properties\"].apply(lambda x: x['Longitude'] if 'Longitude' in x else None)\n",
    "    df[\"isInvasive\"] = True\n",
    "    df[\"source\"] = \"Government\"\n",
    "    df[\"image_url\"] = df[\"properties\"].apply(lambda x: x['Lien_photo'] if 'Lien_photo' in x else None)\n",
    "    df = df[['id', 'species_guess', 'location', 'observation_date', 'isInvasive', 'latitude', 'longitude', 'source', 'image_url']]\n",
    "    df = df[df['location'].isin(['Montreal', 'Laval', 'Gatineau'])]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62d6a621-780e-40c7-bf8e-a66bedd045c5",
     "showTitle": true,
     "title": "Union Community and Government data"
    }
   },
   "outputs": [],
   "source": [
    "# Save the DataFrame as a JSON file with UTF-8 encoding and records orientation\n",
    "gov_df = pd.read_json(\"especes_exo_envahissantes.json\")\n",
    "gov_df = get_government_observations(gov_df)\n",
    "community_df = get_community_observations_df(df_naturalist, df_sentinelle)\n",
    "\n",
    "union_df = pd.concat([community_df, gov_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "835d25f3-2e6f-4468-868e-cfa0c7f38c8f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(gov_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5d06bdb-eccc-4288-be79-4a38450d36eb",
     "showTitle": true,
     "title": "Reading pecarious species data from government and cleaning"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode_outer, col\n",
    "# I want to store in a df the array in the feature field from table\n",
    "df = spark.table(\"hive_metastore.default.animaux_precaire\")\n",
    "\n",
    "def clean_animaux_precaires(df):\n",
    "    df = df.select(explode_outer(col(\"features\"))).select(\"col.properties\").select(\"properties.*\")\n",
    "    animaux_precaires_df = df.toPandas()\n",
    "    cols_animaux_precaires = [\"COSEWIC\", \"GGROUPE\", \"GROUPE\", \"LOIEMV\", \"SCOMNAME\", \"SNAME\"]\n",
    "    animaux_precaires_df = animaux_precaires_df[cols_animaux_precaires].drop_duplicates()\n",
    "    return animaux_precaires_df\n",
    "\n",
    "animaux_precaires_df = clean_animaux_precaires(df)\n",
    "# display(animaux_precaires_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de337fe1-9a3d-4fa4-ad2a-a858fbadb305",
     "showTitle": true,
     "title": "Adding isPrecarious column and saving file to JSON"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def add_isPrecarious_column(observations_df, precarious_df):\n",
    "    df = observations_df.copy()\n",
    "    cols_to_return = list(df) + [\"isPrecarious\"]\n",
    "    \n",
    "    df['species_guess'] = df['species_guess'].astype(str).str.lower()\n",
    "    precarious_df[\"SCOMNAME\"] = precarious_df['SCOMNAME'].astype(str).str.lower()\n",
    "    \n",
    "    merged_df = df.merge(right=precarious_df, left_on='species_guess', right_on='SCOMNAME', how='left')\n",
    "    merged_df[\"isPrecarious\"] = np.where((merged_df[\"SCOMNAME\"].isnull()) | (merged_df[\"SCOMNAME\"] == np.nan), False, True)\n",
    "    \n",
    "    return merged_df[cols_to_return]\n",
    "\n",
    "df_withPrecarious = add_isPrecarious_column(union_df, animaux_precaires_df)\n",
    "display(df_withPrecarious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28245466-0ac2-46c0-afff-042d0ddca9da",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_withPrecarious.to_json(\"observations.json\", orient=\"records\", force_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "66626268-d209-4414-88d0-1e10a889e21a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Creating JSON Files with Species Information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc00cae4-f236-41d6-b6f0-5d61d7b2e3bb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_sentinelle.drop_duplicates().to_json(\"sentinelle_liste_sp.json\", orient=\"records\", force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c7ae39e-8530-4cb9-806c-c84ae8ea680c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "animaux_precaires_df.drop_duplicates().to_json(\"animaux_precaires.json\", orient=\"records\", force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "df4c5b67-648a-4db7-b6c5-1c0aed5d26ff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Inaturalist_dump",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
